{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "145bae5c-44a6-4236-be6d-e731240798a9",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. use pandas read_csv with sep='\\t' to read in the following 2 files available from the us naval academy:\n",
    "- url = 'https://www.usna.edu/Users/cs/nchamber/data/twitter/keyword-tweets.txt'\n",
    "- url = 'https://www.usna.edu/Users/cs/nchamber/data/twitter/general-tweets.txt'\n",
    "<br/> <span style=\"color:red\" float:right>[1 point]</span>\n",
    "\n",
    "2. concatenate these 2 data sets into a single data frame called LabeledTweets that has 2 columns, named Sentiment and Tweet <span style=\"color:red\" float:right>[1 point]</span>\n",
    "\n",
    "3. replace sentiment labels 'POLIT': 1, 'NOT': 0; <span style=\"color:red\" float:right>[0 point]</span>\n",
    "\n",
    "4. clean the tweets\n",
    "   1. remove all tokens that contain a \"@\". Remove the whole token, not just the character.\n",
    "   2. remove all tokens that contain \"http\". Remove the whole token, not just the characters.\n",
    "   3. **replace** (not remove) all punctuation marks with a space (\" \")\n",
    "   4. **replace** all numbers with a space\n",
    "   5. **replace** all non ascii characters with a space\n",
    "   7. convert all characters to lowercase\n",
    "   8. strip extra whitespaces\n",
    "   9. lemmatize tokens\n",
    "   9. No need to remove stopwords because TfidfVectorizer will take care of that\n",
    "<br/><span style=\"color:red\" float:right>[9 point]</span>\n",
    "\n",
    "5. Use TfidfVectorizer from sklearn to prepare the data for machine learning.  Use max_features = 50;  <span style=\"color:red\" float:right>[2 point]</span>\n",
    "\n",
    "6. Use sklearn LogisticRegression to train a model on the  results on 75% of the data. <span style=\"color:red\" float:right>[1 point]</span>\n",
    "\n",
    "7. determine the accuracy on the training data and the test data.   Determine the baseline accuracy. <span style=\"color:red\" float:right>[1 point]</span>\n",
    "\n",
    "8. Repeat steps 5, 6, and 7  with TfidfVectorizer max_features set to 5, 500, 5000, 50000 and discuss your accuracies. <span style=\"color:red\" float:right>[2 point]</span>\n",
    "\n",
    "# End of assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ef93d2-bfb1-49b7-a1ab-7c8c0d4bb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce98133d-cd20-48ef-9072-331e0edb12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3000c01a-3a7a-45d7-b2fa-f10a1eb22dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf98428c-3f88-44be-8311-64393e61034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLIT</td>\n",
       "      <td>Global Voices Online Â» Alex Castro: A liberal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLIT</td>\n",
       "      <td>Do the Conservatives Have a Death Wish? http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOT</td>\n",
       "      <td>@MMFlint I've seen all of your movies and Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLIT</td>\n",
       "      <td>RT @AllianceAlert: * House Dems ask for civili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLIT</td>\n",
       "      <td>RT @AdamSmithInst Quote of the week: My politi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                              Tweet\n",
       "0     POLIT  Global Voices Online Â» Alex Castro: A liberal...\n",
       "1     POLIT  Do the Conservatives Have a Death Wish? http:/...\n",
       "2       NOT  @MMFlint I've seen all of your movies and Capi...\n",
       "3     POLIT  RT @AllianceAlert: * House Dems ask for civili...\n",
       "4     POLIT  RT @AdamSmithInst Quote of the week: My politi..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Use pandas read_csv with sep='\\t' to read in the following 2 files available from the us naval academy\n",
    "\n",
    "# url file:\n",
    "url1 = 'https://www.usna.edu/Users/cs/nchamber/data/twitter/keyword-tweets.txt'\n",
    "col_names = ['Sentiment', 'Tweet']\n",
    "\n",
    "# Download the data\n",
    "usn1 = pd.read_csv(url1, sep='\\t', names = col_names)\n",
    "usn1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267c512b-1dfb-4529-9978-e0e46b247a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOT</td>\n",
       "      <td>Bumping dj sefs mixtape nowww this is my music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT</td>\n",
       "      <td>#ieroween THE STORY OF IEROWEEN! THE VIDEO -&gt;&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOT</td>\n",
       "      <td>trick or treating at the mall today; ZOO! last...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOT</td>\n",
       "      <td>@Ussk81 PMSL!!! I try not to stare but I can't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOT</td>\n",
       "      <td>@Sc0rpi0n676 btw - is there a remote chance i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                              Tweet\n",
       "0       NOT  Bumping dj sefs mixtape nowww this is my music...\n",
       "1       NOT  #ieroween THE STORY OF IEROWEEN! THE VIDEO ->>...\n",
       "2       NOT  trick or treating at the mall today; ZOO! last...\n",
       "3       NOT  @Ussk81 PMSL!!! I try not to stare but I can't...\n",
       "4       NOT  @Sc0rpi0n676 btw - is there a remote chance i ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url file\n",
    "url2 = 'https://www.usna.edu/Users/cs/nchamber/data/twitter/general-tweets.txt'\n",
    "col_names = ['Sentiment', 'Tweet']\n",
    "\n",
    "# Download the data\n",
    "usn2 = pd.read_csv(url2, sep='\\t', names = col_names)\n",
    "usn2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14438f41-aade-40fb-8848-07b2a6106899",
   "metadata": {},
   "source": [
    "**Reason: Use pandas read_csv to upload the data using the provided websites for further analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcfeceb-194d-4a0d-a66c-d4db9838e42b",
   "metadata": {},
   "source": [
    "**Conclusion: Successfully uploaded data from the two provided websites and displayed a portion of data from each website.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97539459-8852-46d3-9afd-ad08ab8e5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Concatenate these 2 data sets into a single data frame called LabeledTweets that has 2 columns, named Sentiment and Tweet\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "LabeledTweets = pd.concat([usn1, usn2], axis=0)\n",
    "\n",
    "# Rename the columns\n",
    "LabeledTweets.columns = ['Sentiment', 'Tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7080170-23ea-4807-b3a0-601bdd1751e5",
   "metadata": {},
   "source": [
    "**Reason: To concatenate the two provided data sets into a single data frame and call it LabeledTweets. Then ensure LabeledTweets has 2 columns named Sentiment and Tweet.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a019df3-40fc-4eea-acc3-18a28d899655",
   "metadata": {},
   "source": [
    "**Conclusion: Successfully concatenated the two dataframes and named the columns Sentiment and Tweet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "050e76e4-03f6-40a1-b0f0-2f4652d67f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Global Voices Online Â» Alex Castro: A liberal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Do the Conservatives Have a Death Wish? http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@MMFlint I've seen all of your movies and Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @AllianceAlert: * House Dems ask for civili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @AdamSmithInst Quote of the week: My politi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                              Tweet\n",
       "0          1  Global Voices Online Â» Alex Castro: A liberal...\n",
       "1          1  Do the Conservatives Have a Death Wish? http:/...\n",
       "2          0  @MMFlint I've seen all of your movies and Capi...\n",
       "3          1  RT @AllianceAlert: * House Dems ask for civili...\n",
       "4          1  RT @AdamSmithInst Quote of the week: My politi..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Replace sentiment labels 'POLIT': 1, 'NOT': 0\n",
    "\n",
    "# Replace sentiment labels\n",
    "LabeledTweets['Sentiment'] = LabeledTweets['Sentiment'].replace({'POLIT': 1, 'NOT': 0})\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "# print(LabeledTweets)\n",
    "LabeledTweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9bb92-d920-4391-a8d8-44dc62b29a1d",
   "metadata": {},
   "source": [
    "**Reason: To replace the sentiment labels Polit with 1 and Not with 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0516f80-8104-4aa0-b3aa-9a12095b7be0",
   "metadata": {},
   "source": [
    "**Conclusion: Successfully created a binary column for Sentiment instead of strings Polit and Not. This will help with further analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a333f-ee1c-4e1a-87bb-4299477f3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Clean the tweets by doing the following:\n",
    "\n",
    "# Removing all tokens that contain a \"@\". Remove the whole token, not just the character.\n",
    "# Removing all tokens that contain \"http\". Remove the whole token, not just the characters.\n",
    "# Replacing (not remove) all punctuation marks with a space (\" \")\n",
    "# Replacing all numbers with a space\n",
    "# Replacing all non ascii characters with a space\n",
    "# Converting all characters to lowercase\n",
    "# Striping the extra whitespaces\n",
    "# Lemmatizing tokens\n",
    "# and remembering not to remove stopwords because TfidfVectorizer will do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ef97634-6c52-4c6e-86d3-517c3fa2be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, list_of_steps):\n",
    "    \n",
    "    for step in list_of_steps:\n",
    "        # step 1 remove entire tokens starting with ampersand\n",
    "        if step == 'remove_amp':\n",
    "            text = ' '.join([x for x in text.split() if not x.startswith(\"@\")])\n",
    "        # step 2 remove entire tokens starting with http    \n",
    "        elif step == 'remove_http':\n",
    "            text = ' '.join([x for x in text.split() if not x.startswith(\"http\")])\n",
    "        # step 3 replace punctuation with space     \n",
    "        elif step == 'replace_punctuation':\n",
    "            punct_exclude = set(string.punctuation)\n",
    "            for char in text:\n",
    "                if char in punct_exclude:\n",
    "                    text = text.replace(char, ' ')\n",
    "        # step 4 replace numbers    \n",
    "        elif step == 'replace_numbers':\n",
    "            for char in text:\n",
    "                try:\n",
    "                    if char.isdigit():\n",
    "                        text = text.replace(char, ' ')\n",
    "                except:\n",
    "                    pass\n",
    "        # step 5 replace non ascii characters with space    \n",
    "        elif step == 'replace_non_ascii':\n",
    "            for char in text:\n",
    "                if ord(char) >= 128:\n",
    "                    text = text.replace(char, ' ')\n",
    "        # step 6 turn all text to lowercase    \n",
    "        elif step == 'lower_case':\n",
    "            text = text.lower()\n",
    "        # step 7 strip the white space    \n",
    "        elif step == 'strip_whitespace':\n",
    "            text = ' '.join(text.split())\n",
    "        # step 8 lemmatizze the words into their stems    \n",
    "        elif step == 'lemmatize':\n",
    "            lmtzr = WordNetLemmatizer()\n",
    "            word_list = text.split(' ')\n",
    "            stemmed_words = [lmtzr.lemmatize(word) for word in word_list]\n",
    "            text = ' '.join(stemmed_words)\n",
    "    # finally return the processed text        \n",
    "    return text\n",
    "\n",
    "# Outline the steps\n",
    "step_list = ['remove_amp', 'remove_http', 'replace_punctuation', 'replace_numbers',\n",
    "            'replace_non_ascii', 'lower_case', 'strip_whitespace', 'lemmatize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9ab4f77-3f96-4999-8ea8-08026f53cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test string\n",
    "test_string = \"@cbigscat // can **12 http//www asoccen''t snwbrd &dggo li,on from aè  LIONSGATE\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53235cb9-c6e9-49f3-a5d9-a1468b831098",
   "metadata": {},
   "source": [
    "**Created a test string to test the steps prior to applying the function to the entire dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c36c95a-df91-4856-a30a-92fe826b83be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can asoccen t snwbrd dggo li on from a lionsgate'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on test string\n",
    "clean_text = clean(test_string, step_list)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b759514-2402-436c-8a44-07b17a19299a",
   "metadata": {},
   "source": [
    "**Testing the steps was a success.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85656b5b-67f1-43de-9b6a-ed0bdbb23b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Global Voices Online Â» Alex Castro: A liberal...</td>\n",
       "      <td>global voice online alex castro a liberal libe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Do the Conservatives Have a Death Wish? http:/...</td>\n",
       "      <td>do the conservative have a death wish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@MMFlint I've seen all of your movies and Capi...</td>\n",
       "      <td>i ve seen all of your movie and capitalism is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @AllianceAlert: * House Dems ask for civili...</td>\n",
       "      <td>rt house dems ask for civility at town hall an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @AdamSmithInst Quote of the week: My politi...</td>\n",
       "      <td>rt quote of the week my political opinion lean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>@themoderngal ditto for me. i am having remors...</td>\n",
       "      <td>ditto for me i am having remorse for all the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>@ceebrito wats goodie my dominican brotha</td>\n",
       "      <td>wats goodie my dominican brotha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>yea my fone iz a DUBB</td>\n",
       "      <td>yea my fone iz a dubb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>@camerongarcia oh yes! My mom wanted to buy my...</td>\n",
       "      <td>oh yes my mom wanted to buy my dog one no thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @RedState: Voter Fraud Video Watch - NJ. ht...</td>\n",
       "      <td>rt voter fraud video watch nj tcot r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4004 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                              Tweet  \\\n",
       "0             1  Global Voices Online Â» Alex Castro: A liberal...   \n",
       "1             1  Do the Conservatives Have a Death Wish? http:/...   \n",
       "2             0  @MMFlint I've seen all of your movies and Capi...   \n",
       "3             1  RT @AllianceAlert: * House Dems ask for civili...   \n",
       "4             1  RT @AdamSmithInst Quote of the week: My politi...   \n",
       "...         ...                                                ...   \n",
       "1995          0  @themoderngal ditto for me. i am having remors...   \n",
       "1996          0          @ceebrito wats goodie my dominican brotha   \n",
       "1997          0                              yea my fone iz a DUBB   \n",
       "1998          0  @camerongarcia oh yes! My mom wanted to buy my...   \n",
       "1999          1  RT @RedState: Voter Fraud Video Watch - NJ. ht...   \n",
       "\n",
       "                                            clean_tweet  \n",
       "0     global voice online alex castro a liberal libe...  \n",
       "1                 do the conservative have a death wish  \n",
       "2     i ve seen all of your movie and capitalism is ...  \n",
       "3     rt house dems ask for civility at town hall an...  \n",
       "4     rt quote of the week my political opinion lean...  \n",
       "...                                                 ...  \n",
       "1995  ditto for me i am having remorse for all the s...  \n",
       "1996                    wats goodie my dominican brotha  \n",
       "1997                              yea my fone iz a dubb  \n",
       "1998   oh yes my mom wanted to buy my dog one no thanks  \n",
       "1999               rt voter fraud video watch nj tcot r  \n",
       "\n",
       "[4004 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the function on df by using the map function linked with the lambda function\n",
    "LabeledTweets['clean_tweet'] = LabeledTweets['Tweet'].map(lambda s: clean(s, step_list))\n",
    "\n",
    "# review dataframe\n",
    "LabeledTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fbf95e1-5685-4676-b4d0-37ebf565fa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment       int64\n",
       "Tweet          object\n",
       "clean_tweet    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabeledTweets.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8eccf-44bd-426a-b3b6-905b0be1aa04",
   "metadata": {},
   "source": [
    "**Checking data types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f679ffd-1ed0-4ece-838d-57fbdf389b02",
   "metadata": {},
   "source": [
    "**Reason:  To clean the tweets for legability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d17f7-6c08-4f00-b4b7-a99f4700ca7e",
   "metadata": {},
   "source": [
    "**Conclusion: Successfully cleaned all the tweets using multiple methods making the tweets more legable compared to what they were originally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9018b84-cf1b-40cf-b428-322ba1052b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Use TfidfVectorizer from sklearn to prepare the data for machine learning. Use max_features = 50; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a55d869-e86c-46f0-93b5-9893f9178609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>afghanistan</th>\n",
       "      <th>all</th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>at</th>\n",
       "      <th>be</th>\n",
       "      <th>but</th>\n",
       "      <th>by</th>\n",
       "      <th>can</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>to</th>\n",
       "      <th>up</th>\n",
       "      <th>wa</th>\n",
       "      <th>we</th>\n",
       "      <th>what</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439826</td>\n",
       "      <td>0.261024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.439826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4004 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      about  afghanistan       all       and  are        at   be  but   by  \\\n",
       "0       0.0          0.0  0.000000  0.489609  0.0  0.000000  0.0  0.0  0.0   \n",
       "1       0.0          0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "2       0.0          0.0  0.439826  0.261024  0.0  0.000000  0.0  0.0  0.0   \n",
       "3       0.0          0.0  0.000000  0.294465  0.0  0.462642  0.0  0.0  0.0   \n",
       "4       0.0          0.0  0.000000  0.363663  0.0  0.000000  0.0  0.0  0.0   \n",
       "...     ...          ...       ...       ...  ...       ...  ...  ...  ...   \n",
       "3999    0.0          0.0  0.401139  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "4000    0.0          0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "4001    0.0          0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "4002    0.0          0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "4003    0.0          0.0  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "      can  ...  time       to        up   wa   we  what  will  with  you  \\\n",
       "0     0.0  ...   0.0  0.00000  0.000000  0.0  0.0   0.0   0.0   0.0  0.0   \n",
       "1     0.0  ...   0.0  0.00000  0.000000  0.0  0.0   0.0   0.0   0.0  0.0   \n",
       "2     0.0  ...   0.0  0.00000  0.439826  0.0  0.0   0.0   0.0   0.0  0.0   \n",
       "3     0.0  ...   0.0  0.00000  0.000000  0.0  0.0   0.0   0.0   0.0  0.0   \n",
       "4     0.0  ...   0.0  0.00000  0.000000  0.0  0.0   0.0   0.0   0.0  0.0   \n",
       "...   ...  ...   ...      ...       ...  ...  ...   ...   ...   ...  ...   \n",
       "3999  0.0  ...   0.0  0.00000  0.000000  0.0  0.0   0.0   0.0   0.0  0.0   \n",
       "4000  0.0  ...   0.0  0.00000  0.000000  0.0  0.0   0.0   0.0   0.0  0.0   \n",
       "4001  0.0  ...   0.0  0.00000  0.000000  0.0  0.0   0.0   0.0   0.0  0.0   \n",
       "4002  0.0  ...   0.0  0.27435  0.000000  0.0  0.0   0.0   0.0   0.0  0.0   \n",
       "4003  0.0  ...   0.0  0.00000  0.000000  0.0  0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "          your  \n",
       "0     0.000000  \n",
       "1     0.000000  \n",
       "2     0.447069  \n",
       "3     0.000000  \n",
       "4     0.000000  \n",
       "...        ...  \n",
       "3999  0.407745  \n",
       "4000  0.000000  \n",
       "4001  0.000000  \n",
       "4002  0.000000  \n",
       "4003  0.000000  \n",
       "\n",
       "[4004 rows x 50 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instance of TfidVectorizer and apply it to the clean tweets column\n",
    "clean_texts = LabeledTweets['clean_tweet']\n",
    "\n",
    "# create a tfidVectorizer instance\n",
    "vectorizer = TfidfVectorizer(max_features = 50)\n",
    "\n",
    "# fit and transform our clean texts to a matrix\n",
    "tfidf_matrix =  vectorizer.fit_transform(clean_texts)\n",
    "\n",
    "# extract the column names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# change the original matrix to a dense array\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# create and review dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_dense, columns = feature_names)\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32adfe9-f744-494e-895a-38160e0d3e9a",
   "metadata": {},
   "source": [
    "**Reason: To use TfidfVectorizer from sklearn to prepare the data for machine learning with the usage of max_features = 50.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1859c73b-b59e-46c7-95ed-0cf78e1ebdaa",
   "metadata": {},
   "source": [
    "**Conclusion: All rows are still here prior to fitting which indicates that the data preservation. Successfully converted the text data into a format that can be used by machine learning algorithms.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01e6abf6-0b44-4445-8626-60875157ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Use sklearn LogisticRegression to train a model on the results on 75% of the data.\n",
    "\n",
    "# 7. Determine the accuracy on the training data and the test data. Determine the baseline accuracy.\n",
    "\n",
    "# 8. Repeat steps 5, 6, and 7 with TfidfVectorizer max_features set to 5, 500, 5000, 50000 and discuss your accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4237d6c3-7b12-4e4b-94dd-906cc94d6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, features are the tfidf_df\n",
    "y_targets = LabeledTweets['Sentiment']\n",
    "\n",
    "# train test split the data into 75, 25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y_targets, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e7e03-f2cc-4751-b61d-7488f40ee3c2",
   "metadata": {},
   "source": [
    "**The TF-IDF dataframe already has the method needed for analysis so I utilize the sentiment values as our targets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29ba7cbf-6739-4631-9679-924bf1c1a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (3003, 50)\n"
     ]
    }
   ],
   "source": [
    "# review shape of training data\n",
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f4d99-b9e3-481b-a8d0-ac775fb0b675",
   "metadata": {},
   "source": [
    "**3,003 is 75% of the original 4,004.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2ad8496-7ace-41df-ae98-960d398cf7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression instance\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict results for both training and testing data\n",
    "train_results = lr.predict(X_train)\n",
    "test_results = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab976712-512b-4cf6-998d-7667ef5e469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8025308025308026\n",
      "Test accuracy: 0.7642357642357642\n",
      "Baseline accuracy: 0.5434565434565435\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for testing and training data and baseline accuracy\n",
    "train_acc = np.mean(y_train == train_results)\n",
    "test_acc = np.mean(y_test == test_results)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))\n",
    "print('Baseline accuracy: {}'.format(np.max([np.mean(y_test == 1), np.mean(y_test == 0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea16665-5c8d-4fb3-931a-444096a63a50",
   "metadata": {},
   "source": [
    "**I set the first model's max_feature parameter to 50. It produces a pretty good predictive model. The test accuracy is at 76% which portrays that it is not overfitting the data and is still giving a higher accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c28ac9bc-5c63-4b27-998f-6d6f04e7fbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80       544\n",
      "           1       0.82      0.62      0.71       457\n",
      "\n",
      "    accuracy                           0.76      1001\n",
      "   macro avg       0.78      0.75      0.75      1001\n",
      "weighted avg       0.77      0.76      0.76      1001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn.metrics to determine accuracy\n",
    "print(classification_report(y_test, test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8b639-54fe-4fec-a44c-043b010fba3c",
   "metadata": {},
   "source": [
    "**With max features set at 50, predictive ability for our algorithm is 80%. Max features at 50 gives enough information for predicting sentiment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d1d4cd6-7afc-42f3-b588-4496e99fd381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature_size': 50, 'accuracy': 0.764}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a running list of dictionaries to hold the feature size and accuracy\n",
    "accuracy_dict = [{'feature_size': 50, 'accuracy': test_acc.round(3)}]\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d7485-f821-4f5e-ad66-76ad2f554418",
   "metadata": {},
   "source": [
    "**Max features set to: 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ffa6326-b8d2-43e0-ac91-f2724fce3f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>of</th>\n",
       "      <th>rt</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.584523</td>\n",
       "      <td>0.659716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472343</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.410944</td>\n",
       "      <td>0.463808</td>\n",
       "      <td>0.418217</td>\n",
       "      <td>0.664155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4004 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           and        of        rt       the   to\n",
       "0     1.000000  0.000000  0.000000  0.000000  0.0\n",
       "1     0.000000  0.000000  0.000000  1.000000  0.0\n",
       "2     0.584523  0.659716  0.000000  0.472343  0.0\n",
       "3     0.700878  0.000000  0.713281  0.000000  0.0\n",
       "4     0.410944  0.463808  0.418217  0.664155  0.0\n",
       "...        ...       ...       ...       ...  ...\n",
       "3999  0.000000  0.000000  0.000000  1.000000  0.0\n",
       "4000  0.000000  0.000000  0.000000  0.000000  0.0\n",
       "4001  0.000000  0.000000  0.000000  0.000000  0.0\n",
       "4002  0.000000  0.000000  0.000000  0.000000  1.0\n",
       "4003  0.000000  0.000000  1.000000  0.000000  0.0\n",
       "\n",
       "[4004 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instance of TfidVectorizer and apply it to the clean tweets column\n",
    "clean_texts = LabeledTweets['clean_tweet']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 5)\n",
    "tfidf_matrix =  vectorizer.fit_transform(clean_texts)\n",
    "# doc = 0\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# create and review dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_dense, columns = feature_names)\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42dc55-fb95-4f74-94cf-53f197a433f3",
   "metadata": {},
   "source": [
    "**This dataframe appears too simplistic to be of use for a sentiment prediction. The words presented are practically all conjunctions or prepositions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e202486-3fe4-497f-8967-48eb7f769a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, features are the tfidf_df\n",
    "y_targets = LabeledTweets['Sentiment']\n",
    "\n",
    "# train test split the data into 75, 25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y_targets, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e514acf-275c-427d-a593-19946fa0b050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (3003, 5)\n"
     ]
    }
   ],
   "source": [
    "# review shape of training data\n",
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a6d483b-1107-40e6-8f43-15c39c936ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression instance\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict results for both training and testing data\n",
    "train_results = lr.predict(X_train)\n",
    "test_results = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0b8d57a-5b56-4fe4-a00a-1b1ff33fad34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.617049617049617\n",
      "Test accuracy: 0.5954045954045954\n",
      "Baseline accuracy: 0.5434565434565435\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for testing and training data and baseline accuracy\n",
    "train_acc = np.mean(y_train == train_results)\n",
    "test_acc = np.mean(y_test == test_results)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))\n",
    "print('Baseline accuracy: {}'.format(np.max([np.mean(y_test == 1), np.mean(y_test == 0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da86c5-349d-4372-a715-8231d2847875",
   "metadata": {},
   "source": [
    "**We only have 5 features which creates a pretty useless model that is correct around 60% of the time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca906835-4cf5-477d-9102-4bdad3884329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64       544\n",
      "           1       0.56      0.51      0.54       457\n",
      "\n",
      "    accuracy                           0.60      1001\n",
      "   macro avg       0.59      0.59      0.59      1001\n",
      "weighted avg       0.59      0.60      0.59      1001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn.metrics to determine accuracy\n",
    "print(classification_report(y_test, test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4256e50-5454-4e1c-a23b-980d151394ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature_size': 50, 'accuracy': 0.764},\n",
       " {'feature_size': 5, 'accuracy': 0.595}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# continue to add to our running list of dictionaries\n",
    "accuracy_dict.append({'feature_size': 5, 'accuracy': test_acc.round(3)})\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07719cd4-94bc-41bc-9639-19059b113df8",
   "metadata": {},
   "source": [
    "**Max features set to: 500**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0086912b-7426-4d0f-8c6b-78312b8f703a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>afghanistan</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>against</th>\n",
       "      <th>all</th>\n",
       "      <th>already</th>\n",
       "      <th>...</th>\n",
       "      <th>www</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4004 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      about  act  action  actually  afghanistan  after  again  against  \\\n",
       "0       0.0  0.0     0.0       0.0          0.0    0.0    0.0      0.0   \n",
       "1       0.0  0.0     0.0       0.0          0.0    0.0    0.0      0.0   \n",
       "2       0.0  0.0     0.0       0.0          0.0    0.0    0.0      0.0   \n",
       "3       0.0  0.0     0.0       0.0          0.0    0.0    0.0      0.0   \n",
       "4       0.0  0.0     0.0       0.0          0.0    0.0    0.0      0.0   \n",
       "...     ...  ...     ...       ...          ...    ...    ...      ...   \n",
       "3999    0.0  0.0     0.0       0.0          0.0    0.0    0.0      0.0   \n",
       "4000    0.0  0.0     0.0       0.0          0.0    0.0    0.0      0.0   \n",
       "4001    0.0  0.0     0.0       0.0          0.0    0.0    0.0      0.0   \n",
       "4002    0.0  0.0     0.0       0.0          0.0    0.0    0.0      0.0   \n",
       "4003    0.0  0.0     0.0       0.0          0.0    0.0    0.0      0.0   \n",
       "\n",
       "           all  already  ...  www   ya  yeah  year       yes  yet   yo  york  \\\n",
       "0     0.000000      0.0  ...  0.0  0.0   0.0   0.0  0.000000  0.0  0.0   0.0   \n",
       "1     0.000000      0.0  ...  0.0  0.0   0.0   0.0  0.000000  0.0  0.0   0.0   \n",
       "2     0.248026      0.0  ...  0.0  0.0   0.0   0.0  0.000000  0.0  0.0   0.0   \n",
       "3     0.000000      0.0  ...  0.0  0.0   0.0   0.0  0.000000  0.0  0.0   0.0   \n",
       "4     0.000000      0.0  ...  0.0  0.0   0.0   0.0  0.000000  0.0  0.0   0.0   \n",
       "...        ...      ...  ...  ...  ...   ...   ...       ...  ...  ...   ...   \n",
       "3999  0.251600      0.0  ...  0.0  0.0   0.0   0.0  0.000000  0.0  0.0   0.0   \n",
       "4000  0.000000      0.0  ...  0.0  0.0   0.0   0.0  0.000000  0.0  0.0   0.0   \n",
       "4001  0.000000      0.0  ...  0.0  0.0   0.0   0.0  0.000000  0.0  0.0   0.0   \n",
       "4002  0.000000      0.0  ...  0.0  0.0   0.0   0.0  0.355827  0.0  0.0   0.0   \n",
       "4003  0.000000      0.0  ...  0.0  0.0   0.0   0.0  0.000000  0.0  0.0   0.0   \n",
       "\n",
       "      you      your  \n",
       "0     0.0  0.000000  \n",
       "1     0.0  0.000000  \n",
       "2     0.0  0.252111  \n",
       "3     0.0  0.000000  \n",
       "4     0.0  0.000000  \n",
       "...   ...       ...  \n",
       "3999  0.0  0.255744  \n",
       "4000  0.0  0.000000  \n",
       "4001  0.0  0.000000  \n",
       "4002  0.0  0.000000  \n",
       "4003  0.0  0.000000  \n",
       "\n",
       "[4004 rows x 500 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instance of TfidVectorizer and apply it to the clean tweets column\n",
    "clean_texts = LabeledTweets['clean_tweet']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 500)\n",
    "tfidf_matrix =  vectorizer.fit_transform(clean_texts)\n",
    "# doc = 0\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# create and review dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_dense, columns = feature_names)\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e1ac0-1b56-4105-8525-5cfddda70dc4",
   "metadata": {},
   "source": [
    "**This data frame appears to be reasonable. Words displayed are relevent and the number of features are deep enough to add value to our predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3aedf17-31c8-4e48-9140-caac623f4a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, features are the tfidf_df\n",
    "y_targets = LabeledTweets['Sentiment']\n",
    "\n",
    "# train test split the data into 75, 25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y_targets, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f6ed284-ba0b-433e-8279-57fbf8a041fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (3003, 500)\n"
     ]
    }
   ],
   "source": [
    "# review shape of training data\n",
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10a26b03-bff9-4990-a3cb-2fa59b3d544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression instance\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict results for both training and testing data\n",
    "train_results = lr.predict(X_train)\n",
    "test_results = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01ed1ed9-8f52-4848-a1c1-76eb8a515817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9140859140859141\n",
      "Test accuracy: 0.8551448551448552\n",
      "Baseline accuracy: 0.5434565434565435\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for testing and training data and baseline accuracy\n",
    "train_acc = np.mean(y_train == train_results)\n",
    "test_acc = np.mean(y_test == test_results)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))\n",
    "print('Baseline accuracy: {}'.format(np.max([np.mean(y_test == 1), np.mean(y_test == 0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c3153-17d2-4134-8250-7a0f49505119",
   "metadata": {},
   "source": [
    "**Max features set to 500  produces a higher accuracy than max features set to 50. I believe we are approaching the overfitting real**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d9c4fae-adc9-4750-a561-5d1b2e02aad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       544\n",
      "           1       0.88      0.80      0.83       457\n",
      "\n",
      "    accuracy                           0.86      1001\n",
      "   macro avg       0.86      0.85      0.85      1001\n",
      "weighted avg       0.86      0.86      0.85      1001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn.metrics to determine accuracy\n",
    "print(classification_report(y_test, test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6e02109-83ea-462f-bf7a-1fb560d782c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature_size': 50, 'accuracy': 0.764},\n",
       " {'feature_size': 5, 'accuracy': 0.595},\n",
       " {'feature_size': 500, 'accuracy': 0.855}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dict.append({'feature_size': 500, 'accuracy':test_acc.round(3)})\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d2cbf-fba2-4183-a06d-c228fa174d83",
   "metadata": {},
   "source": [
    "**Max features set to: 5000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53b4830f-5e54-4379-9355-bc67e07521b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaah</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aan</th>\n",
       "      <th>aarp</th>\n",
       "      <th>ab</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>abroad</th>\n",
       "      <th>...</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yu</th>\n",
       "      <th>zero</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zippity</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4004 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaaaaaaaaaaaaaaaaaaaaah  aaaah  aan  aarp   ab  able  abortion  about  \\\n",
       "0                         0.0    0.0  0.0   0.0  0.0   0.0       0.0    0.0   \n",
       "1                         0.0    0.0  0.0   0.0  0.0   0.0       0.0    0.0   \n",
       "2                         0.0    0.0  0.0   0.0  0.0   0.0       0.0    0.0   \n",
       "3                         0.0    0.0  0.0   0.0  0.0   0.0       0.0    0.0   \n",
       "4                         0.0    0.0  0.0   0.0  0.0   0.0       0.0    0.0   \n",
       "...                       ...    ...  ...   ...  ...   ...       ...    ...   \n",
       "3999                      0.0    0.0  0.0   0.0  0.0   0.0       0.0    0.0   \n",
       "4000                      0.0    0.0  0.0   0.0  0.0   0.0       0.0    0.0   \n",
       "4001                      0.0    0.0  0.0   0.0  0.0   0.0       0.0    0.0   \n",
       "4002                      0.0    0.0  0.0   0.0  0.0   0.0       0.0    0.0   \n",
       "4003                      0.0    0.0  0.0   0.0  0.0   0.0       0.0    0.0   \n",
       "\n",
       "      above  abroad  ...  youth  youtube   yr   yu  zero  zijn  zippity  \\\n",
       "0       0.0     0.0  ...    0.0      0.0  0.0  0.0   0.0   0.0      0.0   \n",
       "1       0.0     0.0  ...    0.0      0.0  0.0  0.0   0.0   0.0      0.0   \n",
       "2       0.0     0.0  ...    0.0      0.0  0.0  0.0   0.0   0.0      0.0   \n",
       "3       0.0     0.0  ...    0.0      0.0  0.0  0.0   0.0   0.0      0.0   \n",
       "4       0.0     0.0  ...    0.0      0.0  0.0  0.0   0.0   0.0      0.0   \n",
       "...     ...     ...  ...    ...      ...  ...  ...   ...   ...      ...   \n",
       "3999    0.0     0.0  ...    0.0      0.0  0.0  0.0   0.0   0.0      0.0   \n",
       "4000    0.0     0.0  ...    0.0      0.0  0.0  0.0   0.0   0.0      0.0   \n",
       "4001    0.0     0.0  ...    0.0      0.0  0.0  0.0   0.0   0.0      0.0   \n",
       "4002    0.0     0.0  ...    0.0      0.0  0.0  0.0   0.0   0.0      0.0   \n",
       "4003    0.0     0.0  ...    0.0      0.0  0.0  0.0   0.0   0.0      0.0   \n",
       "\n",
       "      zombie  zoo   zu  \n",
       "0        0.0  0.0  0.0  \n",
       "1        0.0  0.0  0.0  \n",
       "2        0.0  0.0  0.0  \n",
       "3        0.0  0.0  0.0  \n",
       "4        0.0  0.0  0.0  \n",
       "...      ...  ...  ...  \n",
       "3999     0.0  0.0  0.0  \n",
       "4000     0.0  0.0  0.0  \n",
       "4001     0.0  0.0  0.0  \n",
       "4002     0.0  0.0  0.0  \n",
       "4003     0.0  0.0  0.0  \n",
       "\n",
       "[4004 rows x 5000 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instance of TfidVectorizer and apply it to the clean tweets column\n",
    "clean_texts = LabeledTweets['clean_tweet']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 5000)\n",
    "tfidf_matrix =  vectorizer.fit_transform(clean_texts)\n",
    "# doc = 0\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# create and review dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_dense, columns = feature_names)\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "985b5df2-64c6-4608-a8b0-1b806b3a2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, features are the tfidf_df\n",
    "y_targets = LabeledTweets['Sentiment']\n",
    "\n",
    "# train test split the data into 75, 25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y_targets, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "505d27a2-5b88-49ce-af5c-e1a170928710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (3003, 5000)\n"
     ]
    }
   ],
   "source": [
    "# review shape of training data\n",
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ea98b46-af11-4625-ae9c-292e28746b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression instance\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict results for both training and testing data\n",
    "train_results = lr.predict(X_train)\n",
    "test_results = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a2e00ac-b2f6-49fe-9557-e9e6489a87ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9407259407259407\n",
      "Test accuracy: 0.8471528471528471\n",
      "Baseline accuracy: 0.5434565434565435\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for testing and training data and baseline accuracy\n",
    "train_acc = np.mean(y_train == train_results)\n",
    "test_acc = np.mean(y_test == test_results)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))\n",
    "print('Baseline accuracy: {}'.format(np.max([np.mean(y_test == 1), np.mean(y_test == 0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8108f-8462-40be-8ea9-b87865852450",
   "metadata": {},
   "source": [
    "**Max features set to 5000 seem to drop slightly compared to max features set at 500. Both were still above 80%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3adbf64f-e5e9-4da9-9b9e-eec07a75d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       544\n",
      "           1       0.89      0.76      0.82       457\n",
      "\n",
      "    accuracy                           0.85      1001\n",
      "   macro avg       0.85      0.84      0.84      1001\n",
      "weighted avg       0.85      0.85      0.85      1001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn.metrics to determine accuracy\n",
    "print(classification_report(y_test, test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a76303d7-e9df-4cd7-b94a-86d430b32d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature_size': 50, 'accuracy': 0.764},\n",
       " {'feature_size': 5, 'accuracy': 0.595},\n",
       " {'feature_size': 500, 'accuracy': 0.855},\n",
       " {'feature_size': 5000, 'accuracy': 0.847}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dict.append({'feature_size': 5000, 'accuracy':test_acc.round(3)})\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a028508-e49d-4eaf-b1f9-f43f18ebc08c",
   "metadata": {},
   "source": [
    "**Max features set to: 50000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ea8c7d3-f22d-499a-a5f7-a0ec4f43a88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaah</th>\n",
       "      <th>aaaaaahhhhhhh</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aagghh</th>\n",
       "      <th>aahh</th>\n",
       "      <th>aan</th>\n",
       "      <th>aanslag</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarp</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zombified</th>\n",
       "      <th>zona</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zorgen</th>\n",
       "      <th>zou</th>\n",
       "      <th>zshare</th>\n",
       "      <th>zu</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4004 rows × 10549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaaaaaaaaaaaaaaaaaaaaah  aaaaaahhhhhhh  aaaah  aagghh  aahh  aan  \\\n",
       "0                         0.0            0.0    0.0     0.0   0.0  0.0   \n",
       "1                         0.0            0.0    0.0     0.0   0.0  0.0   \n",
       "2                         0.0            0.0    0.0     0.0   0.0  0.0   \n",
       "3                         0.0            0.0    0.0     0.0   0.0  0.0   \n",
       "4                         0.0            0.0    0.0     0.0   0.0  0.0   \n",
       "...                       ...            ...    ...     ...   ...  ...   \n",
       "3999                      0.0            0.0    0.0     0.0   0.0  0.0   \n",
       "4000                      0.0            0.0    0.0     0.0   0.0  0.0   \n",
       "4001                      0.0            0.0    0.0     0.0   0.0  0.0   \n",
       "4002                      0.0            0.0    0.0     0.0   0.0  0.0   \n",
       "4003                      0.0            0.0    0.0     0.0   0.0  0.0   \n",
       "\n",
       "      aanslag  aaron  aarp   ab  ...  zombified  zona  zone  zoning  zoo  \\\n",
       "0         0.0    0.0   0.0  0.0  ...        0.0   0.0   0.0     0.0  0.0   \n",
       "1         0.0    0.0   0.0  0.0  ...        0.0   0.0   0.0     0.0  0.0   \n",
       "2         0.0    0.0   0.0  0.0  ...        0.0   0.0   0.0     0.0  0.0   \n",
       "3         0.0    0.0   0.0  0.0  ...        0.0   0.0   0.0     0.0  0.0   \n",
       "4         0.0    0.0   0.0  0.0  ...        0.0   0.0   0.0     0.0  0.0   \n",
       "...       ...    ...   ...  ...  ...        ...   ...   ...     ...  ...   \n",
       "3999      0.0    0.0   0.0  0.0  ...        0.0   0.0   0.0     0.0  0.0   \n",
       "4000      0.0    0.0   0.0  0.0  ...        0.0   0.0   0.0     0.0  0.0   \n",
       "4001      0.0    0.0   0.0  0.0  ...        0.0   0.0   0.0     0.0  0.0   \n",
       "4002      0.0    0.0   0.0  0.0  ...        0.0   0.0   0.0     0.0  0.0   \n",
       "4003      0.0    0.0   0.0  0.0  ...        0.0   0.0   0.0     0.0  0.0   \n",
       "\n",
       "      zorgen  zou  zshare   zu   zz  \n",
       "0        0.0  0.0     0.0  0.0  0.0  \n",
       "1        0.0  0.0     0.0  0.0  0.0  \n",
       "2        0.0  0.0     0.0  0.0  0.0  \n",
       "3        0.0  0.0     0.0  0.0  0.0  \n",
       "4        0.0  0.0     0.0  0.0  0.0  \n",
       "...      ...  ...     ...  ...  ...  \n",
       "3999     0.0  0.0     0.0  0.0  0.0  \n",
       "4000     0.0  0.0     0.0  0.0  0.0  \n",
       "4001     0.0  0.0     0.0  0.0  0.0  \n",
       "4002     0.0  0.0     0.0  0.0  0.0  \n",
       "4003     0.0  0.0     0.0  0.0  0.0  \n",
       "\n",
       "[4004 rows x 10549 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instance of TfidVectorizer and apply it to the clean tweets column\n",
    "clean_texts = LabeledTweets['clean_tweet']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 50000)\n",
    "tfidf_matrix =  vectorizer.fit_transform(clean_texts)\n",
    "# doc = 0\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# create and review dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_dense, columns = feature_names)\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53796c26-5cf9-4e49-83b2-15b17d049b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, features are the tfidf_df\n",
    "y_targets = LabeledTweets['Sentiment']\n",
    "\n",
    "# train test split the data into 75, 25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y_targets, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87f04712-0e77-4785-a07c-7284717719b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (3003, 10549)\n"
     ]
    }
   ],
   "source": [
    "# review shape of training data\n",
    "print(type(X_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0204025b-1fe9-450a-a49d-686fe8bbd380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression instance\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# fit model to training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predict results for both training and testing data\n",
    "train_results = lr.predict(X_train)\n",
    "test_results = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc56175-2991-435d-a6d6-f23ed6cc9e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9460539460539461\n",
      "Test accuracy: 0.8381618381618382\n",
      "Baseline accuracy: 0.5434565434565435\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for testing and training data and baseline accuracy\n",
    "train_acc = np.mean(y_train == train_results)\n",
    "test_acc = np.mean(y_test == test_results)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))\n",
    "print('Baseline accuracy: {}'.format(np.max([np.mean(y_test == 1), np.mean(y_test == 0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3398568d-cb81-4341-a240-af0c7eb6f475",
   "metadata": {},
   "source": [
    "**Performance drops a little more with the max features set to 50000. Training accuracy is overfitting the data at this point. For our predictive model, I think we want to use lower max features. The higher number of features starts overfitting with accuracies getting above 90%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71c1ad04-1e4c-424c-aba0-31d6f8c4de0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       544\n",
      "           1       0.89      0.74      0.81       457\n",
      "\n",
      "    accuracy                           0.84      1001\n",
      "   macro avg       0.85      0.83      0.83      1001\n",
      "weighted avg       0.84      0.84      0.84      1001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn.metrics to determine accuracy\n",
    "print(classification_report(y_test, test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07b20b8f-193c-447b-a93a-3c8755e1040e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature_size': 50, 'accuracy': 0.764},\n",
       " {'feature_size': 5, 'accuracy': 0.595},\n",
       " {'feature_size': 500, 'accuracy': 0.855},\n",
       " {'feature_size': 5000, 'accuracy': 0.847},\n",
       " {'feature_size': 50000, 'accuracy': 0.838}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append new values to dictionary\n",
    "accuracy_dict.append({'feature_size': 50000, 'accuracy':test_acc.round(3)})\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d67110a9-a247-498d-887f-2eef37fdc18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TestAccuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_size</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TestAccuracy\n",
       "feature_size              \n",
       "5                    0.595\n",
       "50                   0.764\n",
       "500                  0.855\n",
       "5000                 0.847\n",
       "50000                0.838"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe of accuracy and feature size\n",
    "accuracy_df = pd.DataFrame(accuracy_dict)\n",
    "accuracy_df = accuracy_df.set_index('feature_size')\n",
    "accuracy_df.columns = ['TestAccuracy']\n",
    "\n",
    "# display df\n",
    "accuracy_df = accuracy_df.sort_index(ascending=True)\n",
    "\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e1ed70e-0696-43dc-8e21-257ec56472d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Test Accuracy vs Feature Size'}, xlabel='Log(Feature Size)', ylabel='Percentage (%)'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot on a graph, but take the log of the feature size and convert TestAccuracy to percent\n",
    "x = np.log(list(accuracy_df.index))\n",
    "y = np.array(accuracy_df['TestAccuracy'])*100\n",
    "\n",
    "plt.axes(title='Test Accuracy vs Feature Size', xlabel='Log(Feature Size)', ylabel='Percentage (%)')\n",
    "sns.lineplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ca5dc-ec31-42f5-bfe7-15b8e3302cfa",
   "metadata": {},
   "source": [
    "**Accuracy begins to trend as feature size increases. Predictive test accuracy significantly increases with feature size. Accuracy peaks and then drops slightly as Log(Feature Size) increases.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5422935-6128-40c6-a306-fe8dd23c641e",
   "metadata": {},
   "source": [
    "**Reason: To use sklearn LogisticRegression to train a model on the results on 75% of the data, to determine the accuracy on the training data and the test data. Determine the baseline accuracy, and to repeat steps 5, 6, and 7 with TfidfVectorizer max_features set to 5, 500, 5000, 50000 and discuss your accuracies.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb19581-0f88-4acf-95f4-713839d46633",
   "metadata": {},
   "source": [
    "**Conclusion: Conclusions are spread throughout the analysis. See above.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
