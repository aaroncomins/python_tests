{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7240e7c",
   "metadata": {},
   "source": [
    "# Assignment (Lesson 05)\n",
    "# Data Preparation and Feature Selection\n",
    "Steps in a data science project\n",
    "1. Acquire data\n",
    "2. Exploratory Data analysis (EDA)\n",
    "3. Data Processing\n",
    "    1. Data Preparation\n",
    "    2. Feature Selection\n",
    "4. Predictive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e9c640",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "Python, like most programming languages, has pre-made software methods.  These pre-made software methods are organized and combined by topic into packages.  The packages that we want are:\n",
    "- numpy (numerical python)\n",
    "- pandas (panel data aka tables)\n",
    "- sklearn (sci-kit learn for predictive analytics)\n",
    "- matplotlib (data plotting for matrix-like data)  \n",
    "\n",
    "We need to \"import\" these packages so that we can use their methods in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a30df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "# Allow inline plotting in Jupyter Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e6edfd",
   "metadata": {},
   "source": [
    "## Data Preparation on the Mammographic Masses Dataset (mam)\n",
    "### Acquire data\n",
    "We will get our data from the University of California, Irvine Machine Learning Repository.  Our dataset was used to determine the effectivity of radiological evaluations of breast cancer diagnoses in women who have breast tumors.  You can get some information on the data from here:  http://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a3eae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BI_RADS Age Shape Margin Density  Severity\n",
       "0       5  67     3      5       3         1\n",
       "1       4  43     1      1       ?         1\n",
       "2       5  58     4      5       3         1\n",
       "3       4  28     1      1       3         0\n",
       "4       5  74     1      5       ?         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate data source:\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data\"\n",
    "\n",
    "# Download the data\n",
    "mam = pd.read_csv(url, header=None)\n",
    "\n",
    "# Replace the default column names (0, 1, 2, 3, 4, 5) with meaningful names\n",
    "mam.columns = [\"BI_RADS\", \"Age\", \"Shape\", \"Margin\", \"Density\", \"Severity\"]\n",
    "\n",
    "mam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a29d8",
   "metadata": {},
   "source": [
    "### Some preliminary EDA:\n",
    "\"BI_RADS\", and \"Density\" are ordinal columns.  We will assume that they are numeric.  \n",
    "\"Age\" and \"Severity\" are numeric columns.    \n",
    "\"Shape\" and \"Margin\" are category columns but they are encoded as integers.  \n",
    "\n",
    "Show the actual data types of these columns.  Can you guess why the data types of these 5 columns are `object`?\n",
    "\n",
    "<span style=\"color:red\" float:right>[0 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb44335f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BI_RADS     object\n",
       "Age         object\n",
       "Shape       object\n",
       "Margin      object\n",
       "Density     object\n",
       "Severity     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code here\n",
    "mam.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038580a9-3981-49b3-9735-ca1d960f492a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BI_RADS     False\n",
       "Age         False\n",
       "Shape       False\n",
       "Margin      False\n",
       "Density     False\n",
       "Severity    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My guess is that these are being set to object because of nulls. I can see one just from the 5th row of the head above\n",
    "\n",
    "mam.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb611b3c-8644-42ab-8200-f4d9a963266a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     547\n",
       "5     345\n",
       "3      36\n",
       "2      14\n",
       "6      11\n",
       "0       5\n",
       "?       2\n",
       "55      1\n",
       "Name: BI_RADS, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ah, great, it's even worse than that. They've filled in nulls with values other than NaN.\n",
    "mam.BI_RADS.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738bba83",
   "metadata": {},
   "source": [
    "### Some Data Processing\n",
    "In the following sections you will do the following to the mam dataframe:\n",
    "- Replace unusable entries with null/nan  \n",
    "- Change types of data.\n",
    "- Correct unexpected values (outliers)\n",
    "- decode category data    \n",
    "- Consolidate categories in category data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18542b4",
   "metadata": {},
   "source": [
    "#### Replace Missing Values with Nulls\n",
    "Coerce all columns, even category columns, that contain missing values to numeric data using `pd.to_numeric`.  You might get an error, like `Unable to parse string`.  You need to tell `pd.to_numeric` that it should **coerce** the casting when it encounters a value that it cannot parse.  The category columns in this dataset are encoded as integers.  We will make use of that encoding.  Any non-numeric value will be replaced with a nan and you will get nans for missing numeric and category values.  After you replace all the non-numeric values, present the first five rows with `mam.head()`.\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "056de095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BI_RADS   Age  Shape  Margin  Density  Severity\n",
       "0      5.0  67.0    3.0     5.0      3.0         1\n",
       "1      4.0  43.0    1.0     1.0      NaN         1\n",
       "2      5.0  58.0    4.0     5.0      3.0         1\n",
       "3      4.0  28.0    1.0     1.0      3.0         0\n",
       "4      5.0  74.0    1.0     5.0      NaN         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coerce all the data to numeric data\n",
    "# Coercion will introduce nans/nulls for the non-numeric values in all columns\n",
    "# Because the categories are encoded as integers, the missing categories will also be nans/nulls after coercion.\n",
    "# Add code here\n",
    "mam.BI_RADS = pd.to_numeric(mam.BI_RADS, errors='coerce')\n",
    "mam.Age = pd.to_numeric(mam.Age, errors='coerce')\n",
    "mam.Shape = pd.to_numeric(mam.Shape, errors='coerce')\n",
    "mam.Margin = pd.to_numeric(mam.Margin, errors='coerce')\n",
    "mam.Density = pd.to_numeric(mam.Density, errors='coerce')\n",
    "\n",
    "mam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b03980",
   "metadata": {},
   "source": [
    "#### Replace Outliers\n",
    "Values that are obviously incorrect are often replaced with averages.  Often, outlier replacements with averages are inappropriate because the extreme values have some meaning.  For instance, from the data dictionary we know that BI_RADS should range from 1 to 5.  BI_RADS values beyond 1 and 5 were added by physicians who did not adhere to the accepted range.  In this case, BI_RADS greater than 5 should be \"clipped\" at 5 and BI_RADS less than 1 should be \"clipped\" at 1. \n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7cc12eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap BI_RADS values to a range of 1 to 5\n",
    "# Add code here\n",
    "tooHighRads = mam.BI_RADS > 5\n",
    "mam.loc[tooHighRads, 'BI_RADS'] = 5\n",
    "\n",
    "tooLowRads = mam.BI_RADS < 1\n",
    "mam.loc[tooLowRads, 'BI_RADS'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d30474",
   "metadata": {},
   "source": [
    "### Consolidate and decode category columns\n",
    "\n",
    "Decoding a category is when categories are coded as numbers and we replace those numbers with actual categories.  \n",
    "Consolidating (aka binning or grouping) of categories is means that multiple categories are renamed to a single category.  \n",
    "The decoding and consolidating of categories can occur at the same time.  \n",
    "\n",
    "- Shape\n",
    " - The original category codes are: round=1; oval=2; lobular=3; irregular=4;  \n",
    " - The proper consolidated category decoding is: 1 $\\rightarrow$ oval; 2 $\\rightarrow$ oval; 3 $\\rightarrow$ lobular; 4 $\\rightarrow$ irregular;  \n",
    "- Margin\n",
    " - The orginal category codes are: circumscribed=1; microlobulated=2; obscured=3; ill-defined=4; spiculated=5  \n",
    " - The proper consolidated category decodes are: 1 $\\rightarrow$ circumscribed; 2 $\\rightarrow$ ill-defined; 3 $\\rightarrow$ ill-defined; 4 $\\rightarrow$ ill-defined; 5 $\\rightarrow$ spiculated;\n",
    "\n",
    "After you decode and consolidate, present the first five rows with `mam.head()`. \n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4252a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The category columns are decoded and categories are consolidated\n",
    "\n",
    "\n",
    "# The Shape variable is decoded as follows:  1 and 2 to oval;  3 to lobular; 4 to irregular\n",
    "# Add code here\n",
    "\n",
    "# The Margin variable is decoded as follows:  1 to circumscribed;  2, 3, 4 to ill_defined; 5 to spiculated\n",
    "# Add code here\n",
    "\n",
    "# Present the first few rows\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8859ba29",
   "metadata": {},
   "source": [
    "### Some More EDA\n",
    "- Show the shape of the dataframe\n",
    "- Use the `pandas` `isna` method to show the distribution of nulls among the columns.\n",
    "  \n",
    "<span style=\"color:red\" float:right>[0 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b17cb79d-150e-4ef1-8946-ad465f8b30c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(961, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the shape of the data frame\n",
    "# Add code here\n",
    "mam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b65ad4e-ab67-45f9-8f00-b3fce2b18dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI_RADS: 2 null values out of 961 records (0.21%).\n",
      "Age: 5 null values out of 961 records (0.52%).\n",
      "Shape: 31 null values out of 961 records (3.23%).\n",
      "Margin: 48 null values out of 961 records (4.99%).\n",
      "Density: 76 null values out of 961 records (7.91%).\n",
      "Severity: 0 null values out of 961 records (0.0%).\n"
     ]
    }
   ],
   "source": [
    "# Show the distribution of nulls among the columns\n",
    "# Add code here\n",
    "records = len(mam)\n",
    "\n",
    "for col in mam.columns:\n",
    "    colname = mam[col].name\n",
    "    nulls = mam[col].isna().sum()\n",
    "    print(f'{colname}: {nulls} null values out of {records} records ({round((nulls / records) * 100, 2)}%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e17c12",
   "metadata": {},
   "source": [
    "### Drop Rows with Multiple Missing Values\n",
    "When a row has too many missing values, then it should not be used.  We can stipulate a threshold requirement of available values per row.  We will require that each row contains at least 5 values.  This requirement means that no row is allowed more than 1 missing value.  \n",
    "Remove the rows that have more than one missing value.  \n",
    "- Use the `pandas` `dropna` method and set the `thresh` argument.  \n",
    "- Show the shape of the dataframe after you drop the rows with multiple nulls. \n",
    "- Use the `pandas` `isna` method to show the number of nulls per column after dropping rows with multiple nulls\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e664f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows\n",
    "# Add code here\n",
    "\n",
    "# Show the shape of the data frame\n",
    "# Add code here\n",
    "\n",
    "# Show the distribution of nulls among the columns\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d11c129",
   "metadata": {},
   "source": [
    "## Impute Missing Values\n",
    "Use the median values to impute missing values for true numerical columns (`Age`, `BI_RADS`, `Density`).  `Margin` and `Shape` originally looked numeric, but they are categorical.  Therefore, do not use median on `Margin` and `Shape`.  \n",
    "\n",
    "### Determine the imputation values for Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing age values with the median \n",
    "MedianAge = np.nanmedian(mam.loc[:,\"Age\"])\n",
    "HasNanAge = pd.isnull(mam.loc[:,\"Age\"])\n",
    "print('Now we replace', HasNanAge.sum(),'missing age values with the age median (', MedianAge, ')')\n",
    "mam.loc[HasNanAge, \"Age\"] = MedianAge\n",
    "mam.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056e2c8",
   "metadata": {},
   "source": [
    "### Impute Missing values for BI_RADS and Density\n",
    "Assign the column medians to the null values in the respective numeric columns.\n",
    "- Use the `pandas` `isnull` method to identify the nulls\n",
    "- Use the `numpy` `nanmedian` to determine the median for imputation\n",
    "- Use the `pandas` `isna` method to show the number of nulls per column after the imputation   \n",
    "  \n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1936994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Imputation for BI_RADS\n",
    "# Add code here\n",
    "\n",
    "# Median Imputation for Density\n",
    "# Add code here\n",
    "\n",
    "# Distribution of nulls\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff743b54",
   "metadata": {},
   "source": [
    "### Replace missing values for the two categorical columns\n",
    "- Use `pandas` `value_counts()` method to determine the distribution of categories in `Shape` and `Margin` before imputation.\n",
    "- Use `pandas` `isnull()` method to identify the missing values\n",
    "- Assign the most common value to the null values in the respective categorical columns. \n",
    "- After the imputation, use the `pandas` `isna` method to show the number of nulls after the imputation.\n",
    "- Use `pandas` `value_counts()` method to determine the distribution of categories after imputation.\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the distribution of categories for Shape\n",
    "# Add code here\n",
    "\n",
    "# Replace nulls in Shape with the most common category of Shape\n",
    "# Add code here\n",
    "\n",
    "# Determine the distribution of categories for Margin\n",
    "# Add code here\n",
    "\n",
    "# Replace nulls in Margin with the most common category of Margin\n",
    "# Add code here\n",
    "\n",
    "# Distribution of nulls\n",
    "# Add code here\n",
    "\n",
    "# Determine the distribution of categories\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85baf8",
   "metadata": {},
   "source": [
    "### One hot encode the categorical variables\n",
    "- Use `OneHotEncoder` from `sklearn.preprocessing` to one-hot encode the two categorical variables, `Shape` and `Margin`.\n",
    "- Make sure that the new columns have descriptive hybrid names by using the `get_feature_names_out` method.\n",
    "- Add the new binary columns to the dataframe.\n",
    "- drop the original columns, `Shape` and `Margin`\n",
    "- Show the first few rows of the dataframe.\n",
    "\n",
    "<span style=\"color:red\" float:right>[3 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39de0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get package\n",
    "# Add code here\n",
    "\n",
    "# One-hot-encode\n",
    "# Add code here\n",
    "\n",
    "# Create Column Names\n",
    "# Add code here\n",
    "\n",
    "# Add one-hot-encoded columns to dataframe\n",
    "# Add code here\n",
    "\n",
    "# Drop original categorical columns\n",
    "# Add code here\n",
    "\n",
    "# Show the first few rows\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdda276",
   "metadata": {},
   "source": [
    "## End of Data Preparation on the Mammographic Masses Dataset (mam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085acda4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Feature Selection on the Indian  Liver Patient Dataset (ILPD)\n",
    "Feature selection is a process of removing features that are redundant and that could lead to overfitting, singular matrices, and other problems associated with high cardinality (Curse of dimensionality:  https://en.wikipedia.org/wiki/Curse_of_dimensionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c748d",
   "metadata": {},
   "source": [
    "### Acquire Data\n",
    "\n",
    "We will get our data from the University of California, Irvine Machine Learning Repository. Our dataset was used to determine if blood test data could be sufficient to identify liver disease in rural areas with few physicians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv file:\n",
    "url = \"../data/Indian Liver Patient Dataset (ILPD).csv\"\n",
    "# Alternate data source:\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00225/Indian Liver Patient Dataset (ILPD).csv\"\n",
    "url = url.replace(\" \", \"%20\")\n",
    "\n",
    "# Download the data\n",
    "ILPD = pd.read_csv(url, header=None)\n",
    "\n",
    "# Replace the default column names (0, 1, 2, 3, 4, 5) with meaningful names\n",
    "ILPD.columns = [\"Age\",\"Gender\",\"DB\",\"TB\",\"Alkphos\",\"Sgpt\",\"Sgot\",\"TPr\",\"ALB\",\"AGRatio\",\"Selector\"]\n",
    "\n",
    "ILPD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f483ac1",
   "metadata": {},
   "source": [
    "### Data Preparation for ILPD\n",
    "- All columns should be numeric and continuous\n",
    "    - Remove binary columns (numeric and categorical) because their mutual information scores will be lower\n",
    "    - Remove any categorical columns\n",
    "- Remove or impute any missing values\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b24d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Binary Columns\n",
    "# Add Code here\n",
    "\n",
    "# Impute values or remove rows with nulls\n",
    "# Add Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e49738",
   "metadata": {},
   "source": [
    "### Mutual Information\n",
    "https://en.wikipedia.org/wiki/Mutual_information\n",
    "Below is a wrapper for determining the mutual information between two continuous (numeric) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a181dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "# x is the first input variable\n",
    "# y is the second input variable\n",
    "# bins is the number of discretized values that will be used for the two input variables\n",
    "def calc_MI(x, y, bins=80):\n",
    "    if (bins > 1):\n",
    "        c_xy = np.histogram2d(x, y, bins)[0]\n",
    "        mi = mutual_info_score(None, None, contingency = c_xy)\n",
    "    else:\n",
    "        mi = mutual_info_score(x, y)\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d999c8c2",
   "metadata": {},
   "source": [
    "### Create method to list  all column pairs together with their mutual information score\n",
    "Write a method called `listMutualInformationScores`.  It uses the above method (`calc_MI`) in a loop to find the mutual information between all possible pairs of coulmns in the data.  The input to the function is the dataframe of continuous variables, specifically the prepared ILPD dataset.  \n",
    "\n",
    "The method returns a list of lists.  Each inner list contains three items:  the x-column, the y-column, and the mutual information score. The list of lists contains every possible pair of coulmns in the data.  The result should have a form similar to the following, except that the outer list is much longer and contains all possible column pairs:  \n",
    "`[['Alkphos', 'Sgot', 0.33],\n",
    "['Sgot', 'AGRatio', 0.23],\n",
    "['Age', 'Sgot', 0.35],\n",
    "['Sgpt', 'AGRatio', 0.30],\n",
    "['Sgot', 'ALB', 0.29],\n",
    "['Sgot', 'TPr', 0.33]]`\n",
    "\n",
    "<span style=\"color:red\" float:right>[3 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50586a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the method listMutualInformationScores\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the method listMutualInformationScores\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ae88d",
   "metadata": {},
   "source": [
    "### Present the mutual information results\n",
    "- Package the output into a dataframe\n",
    "- Sort the rows in descending order of mutual information\n",
    "- Present the dataframe\n",
    "\n",
    "The first column could be x, the second column could be called y and the third column could be called mi.  x and y are the pair of columns pair and mi is the pair's mutual information score.  The result should have a form similar to the following:\n",
    "\n",
    "| x | y | mi |\n",
    "| --- | --- | --- |\n",
    "| Age | Sgot | 0.35 |\n",
    "| Sgot | TPr | 0.33 |\n",
    "| Alkphos | Sgot | 0.33 |\n",
    "| Sgpt | AGRatio | 0.30 |\n",
    "| Sgot | ALB | 0.29 |\n",
    "| Sgot | AGRatio | 0.23 |\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present the results as dataframe\n",
    "# Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a86361",
   "metadata": {},
   "source": [
    "### Discussion on Mutual Information in ILPD\n",
    "Lets assume a threshold of 1 for the mutual information score\n",
    "Which columns would you eliminate? Why?  To answer these questions, you may need to read-up on feature selection with mutual information score.\n",
    "\n",
    "<span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe07792d",
   "metadata": {},
   "source": [
    "Add discussion here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebcc24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
